domain waterworld {
	requirements = {
    	concurrent,           // this domain permits multiple non-default actions
        continuous,           // this domain uses real-valued parameterized variables
        cpf-deterministic,    // this domain uses deterministic conditional functions for transitions
        intermediate-nodes,   // this domain uses intermediate pvariable nodes
        reward-deterministic  // this domain does not use a stochastic reward
    };
    types {
    ball: object; //b1, b2, b3...
    dim : object; //x, y
    };
    pvariables {
    	//field setting
    	MIN-ACTION-BOUND: { non-fluent, real, default = -3.5 };
        MAX-ACTION-BOUND: { non-fluent, real, default =  3.5 };
        MIN-VELO-BOUND: { non-fluent, real, default = -3.5 };
        MAX-VELO-BOUND: {non-fluent, real, default = 3.5};
        MAX-FIELD-WIDTH: {non-fluent, real, default = 25};
       //ball setting
        BALL-RADIUS: {non-fluent, real, default= 0.5};
        RED(ball) : { non-fluent, bool, default = false };
        GREEN(ball) : { non-fluent, bool, default = false };
        BLUE(ball) : { non-fluent, bool, default = false };
        ba-velo(ball, dim): {state-fluent, real, default = 0.0};
        ba-loc(ball, dim): {state-fluent, real, default = 0.0};
        if-crash(ball, dim): { interm-fluent, real};
        ba-ag-crash(ball): { interm-fluent, bool};

       //agent setting
        ag-loc(dim): { state-fluent, real, default = 0.0 };
        ag-velo(dim): { state-fluent, real, default = 0.0 };
        ag-move(dim): { action-fluent, real, default = 0.0 };
        if-ag-crash(dim): { interm-fluent, real, level = 1};
        //automata states
    	r:  { interm-fluent, bool };
        g:  { interm-fluent, bool };
        b:  { interm-fluent, bool };
q1: { state-fluent, bool, default = ture};
q2: { state-fluent, bool, default = false};
q3: { state-fluent, bool, default = false};
q4: { state-fluent, bool, default = false};
q5: { state-fluent, bool, default = false};
q6: { state-fluent, bool, default = false};
q7: { state-fluent, bool, default = false};
q8: { state-fluent, bool, default = false};

    };
    cpfs{
    	//ball-move

    	if-crash(?b, ?d) = if(ba-loc(?b, ?d) + ba-velo(?b, ?d) >= MAX-FIELD-WIDTH)
    						then 1
    						else [
    							if(ba-loc(?b, ?d) + ba-velo(?b, ?d) <= 0)
    							then 2
    							else 0
    						];

    	ba-loc'(?b, ?d) = if(if-crash(?b, ?d)==0)
    						then ba-loc(?b, ?d) + ba-velo(?b, ?d)
    						else[
    							if(if-crash(?b, ?d)==1)
    							then MAX-FIELD-WIDTH
    							else 0
    						];

    	ba-velo'(?b, ?d) = if(if-crash(?b, ?d)~=0)
    						then -ba-velo(?b, ?d)
    						else ba-velo(?b, ?d);

    	ba-ag-crash(?b) = if(forall_{?d:dim}((ba-loc(?b, ?d) - ag-loc(?d) <= BALL-RADIUS * 2) ^ (ba-loc(?b, ?d) - ag-loc(?d) >= -BALL-RADIUS*2) ))
    				then true
    				else false;


    	//agent move
    	if-ag-crash(?d) = if(ag-loc(?d) + ag-velo(?d) >= MAX-FIELD-WIDTH)
    						then 1
    						else [
    							if(ag-loc(?d) + ag-velo(?d) <= 0)
    							then 2
    							else 0
    						];

    	ag-loc'(?d) = if(if-ag-crash(?d)==0)
    						then ag-loc(?d) + ag-velo(?d)
    						else[
    							if(if-ag-crash(?d)==1)
    							then MAX-FIELD-WIDTH
    							else 0
    						];

    	ag-velo'(?d) = if(if-ag-crash(?d)~=0)
    						then -ag-velo(?d)
    						else ag-move(?d);

    //event setting
	r =
		if(exists_{?b:ball}(RED(?b) ^ ba-ag-crash(?b)))
		then true
		else false;

	g =
	    if(exists_{?b:ball}(GREEN(?b) ^ ba-ag-crash(?b)))
		then true
		else false;

	b = if(exists_{?b:ball}(BLUE(?b) ^ ba-ag-crash(?b)))
		then true
		else false;

    // DFA translation
    q1' = (q1 ^ (~b^~g^~r));
    q2' = (q1 ^ r) | (q2 ^ (~b^~g^~r));
    q3' = (q2 ^ b) | (q3 ^ (~b^~g^~r));
    q4' = (q3 ^ g) | (q4 ^ (~b^~g^~r));
    q5' = (q4 ^ r) | (q5 ^ (~b^~g^~r));
    q6' = (q5 ^ g) | (q6 ^ (~b^~g^~r));
    q7' = (q6 ^ b) | (q7);
    q8' = (q1 ^ (~r^(b|g))) | (q2 ^ (~b^(g|r))) | (q3 ^ (~g^(b|r))) | (q4 ^ (~r^(b|g))) | (q5 ^ (~g^(b|r))) | (q6^(~b^(g|r))) | (q8);


    };

    reward =  40*q7;
    action-preconditions {
    	forall_{?d:dim} [ag-move(?d) >= MIN-ACTION-BOUND];
        forall_{?d:dim} [ag-move(?d) <= MAX-ACTION-BOUND];

    };

    termination{
    q7;
    q8;
    };

}




